cora:
  M_nodes: 64
  adaptive: false
  add_source: true
  adjoint: false
  adjoint_method: adaptive_heun
  adjoint_step_size: 1
  alpha: 1.0
  alpha_dim: sc
  att_samp_pct: 1
  attention_dim: 128
  attention_norm_idx: 1
  attention_rewiring: false
  attention_type: scaled_dot
  augment: false
  batch_size: 64
  baseline: false
  # batch_norm: false
  beltrami: True
  beta_dim: sc
  block: attention
  cpus: 1
  data_norm: rw
  dataset: Cora
  dataset_dir: ./dataset
  decay: 0.00507685443154266
  directional_penalty: None
  dropout: 0.046878964627763316
  dt: 0.001
  dt_min: 1e-05
  epoch: 300
  exact: true
  fc_out: false
  feat_hidden_dim: 716
  function: laplacian
  gcn: true
  gdc_avg_degree: 64
  gdc_k: 64
  gdc_method: ppr
  gdc_sparsification: topk
  gdc_threshold: 0.01
  gpus: 0.5
  grace_period: 20
  heads: 8
  heat_time: 3.0
  hidden_dim: 1433
  input_dropout: 0.5
  jacobian_norm2: None
  kinetic_energy: None
  label_rate: 0.5
  leaky_relu_slope: 0.2
  lr: 0.001 #0.022924849756740397
  max_epochs: 1000
  max_iters: 100
  max_nfe: 2000
  method: rk4
  metric: MRR
  mix_features: false
  mlp_num_layers: 3
  name: cora_beltrami_splits
  new_edges: random
  no_alpha_sigmoid: false
  no_early: True
  not_lcc: true
  num_init: 1
  num_samples: 1000
  num_splits: 2
  ode_blocks: 1
  optimizer: adamax
  patience: 100
  pos_enc_hidden_dim: 717
  pos_enc_orientation: row
  pos_enc_type: DW1433
  ppr_alpha: 0.05
  reduction_factor: 10
  regularise: false
  reweight_attention: false
  rewire_KNN: false
  rewire_KNN_T: T0
  rewire_KNN_epoch: 10
  rewire_KNN_k: 64
  rewire_KNN_sym: false
  rewiring: None
  rw_addD: 0.02
  rw_rmvR: 0.02
  self_loop_weight: 1
  sparsify: S_hat
  square_plus: true
  step_size: 1
  threshold_type: addD_rvR
  time: 18.294754260552843
  tol_scale: 821.9773048827274
  tol_scale_adjoint: 1.0
  total_deriv: None
  use_cora_defaults: false
  use_flux: false
  use_labels: false
  use_lcc: true
  use_mlp: false
  use_valedges_as_input: false
